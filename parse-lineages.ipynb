{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openpyxl pypyodbc pandas ipykernel sqlglot(forked)\n",
    "import pypyodbc as odbc\n",
    "from sqlglot import parse_one, exp\n",
    "from sqlglot.dialects.tsql import TSQL\n",
    "from sqlglot.dialects.ma import MA\n",
    "import configparser\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict \n",
    "import pandas as pd\n",
    "import pypyodbc as odbc\n",
    "import configparser\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from modules.sql_parser.parse_lineages import *\n",
    "from modules.sql_parser.parse_nodes import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>NAME_NODE</th>\n",
       "      <th>LABEL_NODE</th>\n",
       "      <th>FILTER</th>\n",
       "      <th>FUNCTION</th>\n",
       "      <th>ON</th>\n",
       "      <th>COLOR</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>query_INVESTOR_ANALYSIS</td>\n",
       "      <td>query_INVESTOR_ANALYSIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>query</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#42d6a4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>INVESTOR_ANALYSIS</td>\n",
       "      <td>INVESTOR_ANALYSIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>target</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#42d6a4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\"dbo\".\"Investors_Extract\"</td>\n",
       "      <td>\"dbo\".\"Investors_Extract\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DataSources</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#42d6a4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>query_SUPPLIERS_ANALYSIS</td>\n",
       "      <td>query_SUPPLIERS_ANALYSIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>query</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#42d6a4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SUPPLIERS_ANALYSIS</td>\n",
       "      <td>SUPPLIERS_ANALYSIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>target</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#42d6a4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  NAME_NODE                 LABEL_NODE  FILTER  \\\n",
       "0           0    query_INVESTOR_ANALYSIS    query_INVESTOR_ANALYSIS     NaN   \n",
       "1           1          INVESTOR_ANALYSIS          INVESTOR_ANALYSIS     NaN   \n",
       "2           2  \"dbo\".\"Investors_Extract\"  \"dbo\".\"Investors_Extract\"     NaN   \n",
       "3           3   query_SUPPLIERS_ANALYSIS   query_SUPPLIERS_ANALYSIS     NaN   \n",
       "4           4         SUPPLIERS_ANALYSIS         SUPPLIERS_ANALYSIS     NaN   \n",
       "\n",
       "      FUNCTION  ON    COLOR  ID  \n",
       "0        query NaN  #42d6a4   0  \n",
       "1       target NaN  #42d6a4   1  \n",
       "2  DataSources NaN  #42d6a4   2  \n",
       "3        query NaN  #42d6a4   3  \n",
       "4       target NaN  #42d6a4   4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "queries = [] # queries content list\n",
    "files = [] # file names list\n",
    "for file in os.listdir(\"data/preprocessed-queries/\"):\n",
    "    files.append(file.split('.')[0])\n",
    "    with open(f'data/preprocessed-queries/{file}', 'r') as file:\n",
    "        data = json.load(file)\n",
    "    queries.append(data)\n",
    "\n",
    "# load nodes dataset\n",
    "nodes = pd.read_csv('data/output-tables/nodes.csv')\n",
    "nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUM(total_amount)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def SQL_transf(query, inputl = \"tsql\", outputl = \"ma\"):\n",
    "    \"\"\" \n",
    "    Function is designed to extract all the functions from a given sql script and convert them into the desired\n",
    "    dialect. Returns a list of tuples where the first element is the recognised function and the second one\n",
    "    is the redesigned function. The first argument is the raw query that needs translation, and it always\n",
    "    has to be accompanied by a starting SELECT statement. Second argument is the lookup list that should contain all\n",
    "    the function keywords that need to be looked for within the raw query. inputl and outputl are the input language and\n",
    "    the output language respectively. \n",
    "    \"\"\"\n",
    "    pattern = r'\\$\\$([^$]+?)\\$\\$'  # Modified regex pattern to capture the variable\n",
    "    matches = re.findall(pattern, query)\n",
    "    \n",
    "    if matches:\n",
    "        for var_name in matches:\n",
    "            new_string = f'\"{var_name}\"'\n",
    "            query = re.sub(rf\"\\'\\$\\${re.escape(var_name)}\\$\\$\\'\", new_string, query)\n",
    "         \n",
    "    df_tf = pd.read_excel('data/functions.xlsx')\n",
    "    flookup = list(df_tf[\"Parser Keyword\"])\n",
    "    ast = parse_one(query, dialect = inputl)\n",
    "    \n",
    "    org_columns = list(ast.find_all(exp.Column))\n",
    "    cleaned_columns = []\n",
    "    \n",
    "    for element in org_columns:\n",
    "        if \"$\" in element.name:\n",
    "            cleaned_columns.append((element.name,element.name.replace(\"$\", \"\")))\n",
    "  \n",
    "    def transformer_column(node):\n",
    "        for element in cleaned_columns:\n",
    "            if isinstance(node, exp.Column) and node.name == element[0]:\n",
    "                return parse_one('\"'+element[1]+'\"')\n",
    "        return node\n",
    "\n",
    "    cleaned_tree = ast.transform(transformer_column)\n",
    "\n",
    "    general_syntax= []\n",
    "    transformations = []\n",
    "    scripts = []\n",
    "    for i in flookup:    \n",
    "        o = list(cleaned_tree.find_all(getattr(exp, i)))\n",
    "        for element in o:\n",
    "            general_syntax.append(element.sql(dialect = outputl))\n",
    "            scripts.append(repr(element))\n",
    "            if len(o)>0:\n",
    "                transformations.append(i)\n",
    "        \n",
    "    matched = list(zip(transformations, general_syntax))  \n",
    "    \n",
    "    mother_expressions = []\n",
    "    for expression1 in matched:\n",
    "        is_mother = True\n",
    "        for expression2 in matched:\n",
    "            if expression1[1] != expression2[1] and expression1[1] in expression2[1]:\n",
    "                is_mother = False\n",
    "                break\n",
    "            \n",
    "        if is_mother: \n",
    "            mother_expressions.append(expression1)\n",
    "       \n",
    "    ifs = []\n",
    "    cases = []\n",
    "    \n",
    "    for i, element in list(enumerate(mother_expressions)):\n",
    "        if element[0] == \"If\":\n",
    "            ifs.append((i,element[1].replace(\" \",\"\").replace(\"(\", \"\").replace(\")\", \"\").strip(\"IFTHENELSE\")))\n",
    "        elif element[0] == \"Case\":\n",
    "            cases.append((i, element[1].replace(\" \",\"\").replace(\"(\", \"\").replace(\")\", \"\").strip(\"IFTHENELSE\")))\n",
    "    \n",
    "    singular_if = []\n",
    "    for element in ifs:\n",
    "        main = False\n",
    "        for i in cases:\n",
    "           if element[1] in i[1]:\n",
    "                main = True\n",
    "        if main:\n",
    "            singular_if.append(element)\n",
    "    \n",
    "    index_remove =[]\n",
    "    for element in singular_if:\n",
    "        index_remove.append(element[0])\n",
    "    \n",
    "    list_remove=[]\n",
    "    for element in index_remove:\n",
    "        for l in mother_expressions:\n",
    "            if element == mother_expressions.index(l):\n",
    "                list_remove.append(l)\n",
    "            \n",
    "    for element in list_remove:\n",
    "        mother_expressions.remove(element)\n",
    "    \n",
    "    return mother_expressions[0][1]\n",
    "\n",
    "\n",
    "\n",
    "SQL_transf('SUM(total_amount)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json_data0\n",
      "[]\n",
      "['INVESTOR_ANALYSIS.Discount', 'INVESTOR_ANALYSIS.Discount']\n",
      "json_data1\n",
      "['SUPPLIERS_ANALYSIS.id']\n",
      "['SUPPLIERS_ANALYSIS.Name']\n",
      "['SUPPLIERS_ANALYSIS.Entity']\n",
      "['SUPPLIERS_ANALYSIS.Discount']\n",
      "['SUPPLIERS_ANALYSIS.Discount', 'SUPPLIERS_ANALYSIS.Discount']\n"
     ]
    }
   ],
   "source": [
    "# extract lineages\n",
    "\n",
    "lineages_dfs = []\n",
    "trees = []\n",
    "queries=[]\n",
    "for i, file in enumerate(os.listdir(\"data/preprocessed-queries/\")):\n",
    "    filename = file.split('.')[0]\n",
    "    print(filename)\n",
    "    files.append(file.split('.')[0])\n",
    "    with open(f'data/preprocessed-queries/{file}', 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    queries.append(data)\n",
    "\n",
    "    # reverse subqueries dict to start from deepest level\n",
    "    query_subqueries = dict(reversed(list(queries[i]['subquery_dictionary'].items())))\n",
    "    query_subqueries['main_query'] = queries[i]['modified_SQL_query']\n",
    "    query_subqueries\n",
    "\n",
    "    lineages = [] # list of dictionaries with the nodes\n",
    "\n",
    "    for name_query in query_subqueries:\n",
    "\n",
    "        query = query_subqueries[name_query]\n",
    "\n",
    "        if query.startswith(\"(\"):\n",
    "            query = query.strip(\"()\")\n",
    "        else:\n",
    "            pass\n",
    "        ast = parse_query(query) # get parsed tree\n",
    "\n",
    "        if 'subquery' in name_query: # if the query is a subquery then the name is the dict key, else the name is the target table\n",
    "            target_node = name_query\n",
    "            target_columns =[]\n",
    "\n",
    "        else:\n",
    "            target_columns =[]\n",
    "\n",
    "            try: # try with create table statement\n",
    "                target_node = list(ast.find_all(exp.Create))[0].this.this.this\n",
    "            except IndexError: # else try with insert into table statement\n",
    "                target_node = list(ast.find_all(exp.Insert))[0].this.this\n",
    "\n",
    "                insert_obj = list(ast.find_all(exp.Insert))[0]\n",
    "                target_columns = list(insert_obj.find_all(exp.Column))\n",
    "                target_columns = [[i] for i in target_columns]\n",
    "                \n",
    "\n",
    "        space_table = find_table_w_spaces(ast) # list with tables with spaces (sqlglot cant parse them)\n",
    "\n",
    "        space_table = list(set(space_table)) # a list of tuples with table names paired (space removed original - original ) Eg. (OrderDetails, Order Details)\n",
    "\n",
    "        alias_table = get_tables(ast) # parse table name + table alias\n",
    "\n",
    "        tree = replace_aliases(query) # transform query by removing table aliases\n",
    "\n",
    "        if target_columns == []:\n",
    "            select_statement, target_columns = extract_target_columns(tree) # extract target columns\n",
    "        else:\n",
    "            select_statement, x = extract_target_columns(tree) # extract target columns\n",
    "\n",
    "\n",
    "        replaced_trees = [x.transform(transformer_functions) for x in select_statement] # replace columns aliases\n",
    "        trees.append(replaced_trees)\n",
    "\n",
    "        # add possible transformation to columns\n",
    "        transformations = extract_transformation(replaced_trees)\n",
    "        target_columns = list(zip(target_columns, transformations)) \n",
    "\n",
    "        query_node = f'query_{target_node}'\n",
    "        \n",
    "        lineages = extract_source_target_transformation(target_columns, lineages, space_table, query_node, target_node) # append lineages of node to list\n",
    "\n",
    "\n",
    "    lineages = pd.DataFrame(lineages)\n",
    "\n",
    "    lineages = lineages.explode('SOURCE_COLUMNS').reset_index()\n",
    "\n",
    "    lineages['FILE_NAME'] = filename\n",
    "    lineages['ROW_ID'] = 0\n",
    "    lineages['LINK_VALUE'] = 1\n",
    "\n",
    "    lineages['SOURCE_NODE'] = lineages['SOURCE_COLUMNS'].apply(lambda x:\".\".join(x.split('.')[0:-1]))\n",
    "    lineages['TARGET_NODE'] = lineages['TARGET_COLUMN'].apply(lambda x:\".\".join(x.split('.')[0:-1]))\n",
    "\n",
    "    lineages['SOURCE_FIELD'] = lineages['SOURCE_COLUMNS'].apply(lambda x:x.split('.')[-1])\n",
    "    lineages['TARGET_FIELD'] = lineages['TARGET_COLUMN'].apply(lambda x:x.split('.')[-1])\n",
    "\n",
    "    lineages['SOURCE_NODE'] = [f'{filename}@{i}' if 'subquery' in i else i for i in lineages['SOURCE_NODE'] ]\n",
    "    lineages['TARGET_NODE'] = [f'{filename}@{i}' if 'subquery' in i else i for i in lineages['TARGET_NODE']]\n",
    "\n",
    "\n",
    "    lineages['COLOR'] =  [\"aliceblue\" if i == \"\" else \"orangered\" for i in lineages['TRANSFORMATION']]\n",
    "\n",
    "    # merge source id\n",
    "    lineages = pd.merge(lineages, nodes[['ID', 'LABEL_NODE']], left_on='SOURCE_NODE', right_on = 'LABEL_NODE', how='left')\n",
    "    lineages['SOURCE_NODE'] = lineages['ID']\n",
    "    lineages.drop(columns=['ID', 'LABEL_NODE'], inplace=True)\n",
    "\n",
    "    # merge target id\n",
    "    lineages = pd.merge(lineages, nodes[['ID', 'LABEL_NODE']], left_on='TARGET_NODE', right_on = 'LABEL_NODE', how='left')\n",
    "    lineages['TARGET_NODE'] = lineages['ID']\n",
    "    lineages.drop(columns=['ID', 'LABEL_NODE'], inplace=True)\n",
    "\n",
    "    lineages = lineages.drop_duplicates(subset =['SOURCE_COLUMNS', 'TARGET_COLUMN', 'TRANSFORMATION']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    lineages.to_csv(f\"data/output-tables/lineages/lineage-{target_node}.csv\")\n",
    "    lineages_dfs.append(lineages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>SOURCE_COLUMNS</th>\n",
       "      <th>TARGET_COLUMN</th>\n",
       "      <th>TRANSFORMATION</th>\n",
       "      <th>FILE_NAME</th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>LINK_VALUE</th>\n",
       "      <th>SOURCE_NODE</th>\n",
       "      <th>TARGET_NODE</th>\n",
       "      <th>SOURCE_FIELD</th>\n",
       "      <th>TARGET_FIELD</th>\n",
       "      <th>COLOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>INVESTOR_ANALYSIS.Discount</td>\n",
       "      <td>query_INVESTOR_ANALYSIS.DiscountCategory</td>\n",
       "      <td>IFTHENELSE(EQ(Discount, 0), 'C', EQ(Discount, ...</td>\n",
       "      <td>json_data0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Discount</td>\n",
       "      <td>DiscountCategory</td>\n",
       "      <td>orangered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>query_INVESTOR_ANALYSIS.DiscountCategory</td>\n",
       "      <td>INVESTOR_ANALYSIS.DiscountCategory</td>\n",
       "      <td></td>\n",
       "      <td>json_data0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>DiscountCategory</td>\n",
       "      <td>DiscountCategory</td>\n",
       "      <td>aliceblue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                            SOURCE_COLUMNS  \\\n",
       "0      0                INVESTOR_ANALYSIS.Discount   \n",
       "1      1  query_INVESTOR_ANALYSIS.DiscountCategory   \n",
       "\n",
       "                              TARGET_COLUMN  \\\n",
       "0  query_INVESTOR_ANALYSIS.DiscountCategory   \n",
       "1        INVESTOR_ANALYSIS.DiscountCategory   \n",
       "\n",
       "                                      TRANSFORMATION   FILE_NAME  ROW_ID  \\\n",
       "0  IFTHENELSE(EQ(Discount, 0), 'C', EQ(Discount, ...  json_data0       0   \n",
       "1                                                     json_data0       0   \n",
       "\n",
       "   LINK_VALUE  SOURCE_NODE  TARGET_NODE      SOURCE_FIELD      TARGET_FIELD  \\\n",
       "0           1            1            0          Discount  DiscountCategory   \n",
       "1           1            0            1  DiscountCategory  DiscountCategory   \n",
       "\n",
       "       COLOR  \n",
       "0  orangered  \n",
       "1  aliceblue  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineages_dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineages_dfs.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineages_dfs[0]['TRANSFORMATION'][1] \n",
    "\n",
    "# target node in case of insert into should also include the new columns\n",
    "# when two columns are multiplied that does not count as transformation, fix that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rabo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
